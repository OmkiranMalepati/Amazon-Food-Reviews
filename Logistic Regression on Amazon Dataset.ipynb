{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      Id   ProductId          UserId                  ProfileName  \\\n",
      "0  138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
      "1  138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
      "2  138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
      "3  138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
      "4  138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "0                     0                       0  Positive   939340800   \n",
      "1                     1                       1  Positive  1194739200   \n",
      "2                     1                       1  Positive  1191456000   \n",
      "3                     1                       1  Positive  1076025600   \n",
      "4                     3                       4  Positive  1018396800   \n",
      "\n",
      "                                      Summary  \\\n",
      "0                   EVERY book is educational   \n",
      "1  Love the book, miss the hard cover version   \n",
      "2               chicken soup with rice months   \n",
      "3      a good swingy rhythm for reading aloud   \n",
      "4             A great way to learn the months   \n",
      "\n",
      "                                                Text  \\\n",
      "0  this witty little book makes my son laugh at l...   \n",
      "1  I grew up reading these Sendak books, and watc...   \n",
      "2  This is a fun way for children to learn their ...   \n",
      "3  This is a great little book to read aloud- it ...   \n",
      "4  This is a book of poetry about the months of t...   \n",
      "\n",
      "                                        Cleaned_Text  \n",
      "0  b'witti littl book make son laugh loud recit c...  \n",
      "1  b'grew read sendak book watch realli rosi movi...  \n",
      "2  b'fun way children learn month year learn poem...  \n",
      "3  b'great littl book read nice rhythm well good ...  \n",
      "4  b'book poetri month year goe month cute littl ...  \n",
      "      index      Id   ProductId          UserId                 ProfileName  \\\n",
      "19   138708  150526  0006641040  A3E9QZFE9KXH8J                 R. Mitchell   \n",
      "29   138679  150497  0006641040  A1HKYQOFC8ZZCH  Maria Apolloni \"lanarossa\"   \n",
      "36    22620   24750  2734888454  A13ISQV0U9GZIC                   Sandikaye   \n",
      "156  157869  171180  7310172001  A2WDF9UM0M1VAD              susan m. kaitz   \n",
      "191  157873  171186  7310172001  A12OC9ZA779927     Nancy Watts \"Nan Watts\"   \n",
      "\n",
      "     HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "19                     11                      18  Negative  1129507200   \n",
      "29                      2                       2  Negative  1334707200   \n",
      "36                      1                       1  Negative  1192060800   \n",
      "156                     3                       6  Negative  1317859200   \n",
      "191                     1                      22  Negative  1134172800   \n",
      "\n",
      "                                               Summary  \\\n",
      "19                              awesome book poor size   \n",
      "29   The story is great, the softcover book is disa...   \n",
      "36                                       made in china   \n",
      "156       Review of Freeze Dried Liver Treats For Dogs   \n",
      "191  no shipping charges in December if over $50 on...   \n",
      "\n",
      "                                                  Text  \\\n",
      "19   This is one of the best children's books ever ...   \n",
      "29   I give five stars to the Maurice Sendak story....   \n",
      "36   My dogs loves this chicken but its a product f...   \n",
      "156  I received all containers previously opened - ...   \n",
      "191                  Same price as Dr. Foster & Smith.   \n",
      "\n",
      "                                          Cleaned_Text  \n",
      "19   b'one best children book ever written mini ver...  \n",
      "29   b'give five star mauric sendak stori one star ...  \n",
      "36   b'dog love chicken product china wont buy anym...  \n",
      "156  b'receiv contain previous open seal open top c...  \n",
      "191                              b'price foster smith'  \n",
      "(10000, 14180)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "con = sqlite3.connect(\"D:/Data_Practice/final.sqlite\")\n",
    "\n",
    "processed_data = pd.read_sql_query('''SELECT * FROM Reviews''',con)\n",
    "processed_data.shape\n",
    "processed_data.head()\n",
    "\n",
    "final_pos = processed_data[processed_data.Score=='Positive']\n",
    "final_pos.shape\n",
    "\n",
    "final_neg = processed_data[processed_data.Score=='Negative']\n",
    "final_neg.shape\n",
    "\n",
    "final_pos_5000 = final_pos[0:5000]\n",
    "final_pos_5000.shape\n",
    "print(final_pos_5000.head(5))\n",
    "\n",
    "final_neg_5000 = final_neg[0:5000]\n",
    "final_neg_5000.shape\n",
    "print(final_neg_5000.head(5))\n",
    "\n",
    "final_10000 = pd.concat([final_pos_5000 , final_neg_5000],axis=0,ignore_index=True)\n",
    "final_10000.tail()\n",
    "\n",
    "sample = final_10000.sort_values(by='Time')\n",
    "score_10000 = sample['Score']\n",
    "sample.head()\n",
    "sample['Score'].value_counts()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(ngram_range=(1,1))\n",
    "final_bow = count_vect.fit_transform(sample['Cleaned_Text'].values)\n",
    "print(final_bow.shape)\n",
    "#Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "std_data = scaler.fit_transform(final_bow.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    5000\n",
       "Negative    5000\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cf763250a359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtsne_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtsne_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m         \"\"\"\n\u001b[1;32m--> 886\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'barnes_hut'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             raise ValueError(\"'n_components' should be inferior to 4 for the \"\n\u001b[0m\u001b[0;32m    688\u001b[0m                              \u001b[1;34m\"barnes_hut algorithm as it relies on \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m                              \"quad-tree or oct-tree.\")\n",
      "\u001b[1;31mValueError\u001b[0m: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree."
     ]
    }
   ],
   "source": [
    "#Dim Red is optional\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=3,random_state=0)\n",
    "tsne_data = model.fit_transform(final_dense)\n",
    "tsne_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(std_data)\n",
    "score_1000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_1000 = std_data[0:10000]\n",
    "score_1000 = score_10000[0:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.9627142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#data = load_breast cancer() refer: http://scikit-learn.org/stable/modules/\n",
    "\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10, 100, 10**3]}]\n",
    "\n",
    "X = std_data #We give entire dim without tSNE here\n",
    "Y = score_10000\n",
    "\n",
    "x_1,x_test,y_1,y_test = train_test_split(X,Y,test_size=0.3,random_state=10)#70 - 30\n",
    "#x_tr,x_cv,y_tr,y_cv   = train_test_split(x_1,y_1,test_size=0.3,random_state=10) # 70% of 70-->x_tr;30% of 70 -->x_cv/y_cv\n",
    "#x_tr = 73,x_cv=32,x_test=45 and same y's also\n",
    "\n",
    "#Using GridSearchcv\n",
    "\n",
    "model = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy')\n",
    "\n",
    "model.fit (x_1, y_1)\n",
    "\n",
    "print(model.best_estimator_) \n",
    "print (model.score(x_1, y_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.26666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(C=0.0001,penalty='l2')\n",
    "clf.fit(x_1,y_1)\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    " \n",
    "acc = accuracy_score(y_test,pred)*100\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
